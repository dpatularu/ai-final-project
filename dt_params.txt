https://scikit-learn.org/stable/modules/tree.html
	scikit-learn uses CART algorithm for DT

DecisionTreeClassifier
	classifier (default gini)
		gini vs entropy(information gain)
		small impact (~2%)
		gini is significantly faster
	
	splitter (defualt best)
		best vs random
		small impact
		random combats overfitting at cost of accuracy
	
	max_depth (default 0)
		high impact
		too low -> underfit
		too high -> overfit
	
	min_samples_split (default 2)
		highest impact*
		values tend to be between 1 and 40
		high values used to combat overfitting
		can cause underfitting if pushed too high
	
	min_samples_leaf (default 1)
		highest impact*
		tend to 1-20
		also controls overfitting
	
	max_features (default none)
		sqrt, log, or const fraction (float)
		combats overfitting 
			(sqrt, log, float) from least to most
	
	min_weight_fraction_leaf (default 0)
		gives min_samples_leaf more impact
	
	min_impurity_decrease (default 0)
		black magic
	